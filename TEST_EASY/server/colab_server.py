"""
TEST_EASY Colab Server
=======================

–¶–µ–π —Å–∫—Ä–∏–ø—Ç —Ä–æ–∑—Ä–∞—Ö–æ–≤–∞–Ω–æ –Ω–∞ –∑–∞–ø—É—Å–∫ —É Google Colab.
–ó–∞–ø—É—Å—Ç—ñ—Ç—å —Ü–µ–π —Ñ–∞–π–ª —è–∫ notebook —É Colab —Ç–∞ –æ—Ç—Ä–∏–º–∞–π—Ç–µ –ø—É–±–ª—ñ—á–Ω–µ –ø–æ—Å–∏–ª–∞–Ω–Ω—è –¥–ª—è –∫–ª—ñ—î–Ω—Ç–∞.

–í—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è:
1. –°—Ç–≤–æ—Ä—ñ—Ç—å –Ω–æ–≤–∏–π Colab notebook
2. –ó–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ —Ü–µ–π —Ñ–∞–π–ª —è–∫ notebook (–∞–±–æ —Å–∫–æ–ø—ñ—é–π—Ç–µ –∫–æ–¥)
3. –ó–∞–ø—É—Å—Ç—ñ—Ç—å –∫–ª—ñ—Ç–∏–Ω–∫–∏ –ø–æ –ø–æ—Ä—è–¥–∫—É
4. –û—Ç—Ä–∏–º–∞–π—Ç–µ URL —Ç–∞ –ø–æ–¥—ñ–ª—ñ—Ç—å—Å—è –∑ –∫–ª—ñ—î–Ω—Ç–æ–º
"""

# ============================================================================
# üì¶ –ö–õ–Ü–¢–ò–ù–ö–ê 1: –í—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è –∑–∞–ª–µ–∂–Ω–æ—Å—Ç–µ–π
# ============================================================================

# !pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
# !pip install diffusers transformers accelerate safetensors pyngrok flask flask-cors pillow

# ============================================================================
# üì¶ –ö–õ–Ü–¢–ò–ù–ö–ê 2: –Ü–º–ø–æ—Ä—Ç–∏ —Ç–∞ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è
# ============================================================================

import os
import sys
import torch
import json
from pathlib import Path
from PIL import Image
import base64
import io
from typing import Dict, Optional

# –î–ª—è Flask —Å–µ—Ä–≤–µ—Ä–∞
from flask import Flask, request, jsonify
from flask_cors import CORS
from werkzeug.exceptions import BadRequest

# –î–ª—è ngrok —Ç—É–Ω–µ–ª—é
try:
    from pyngrok import ngrok
except ImportError:
    ngrok = None
    print("‚ö†Ô∏è  ngrok –Ω–µ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")

# –î—Ä—É–∫—É—î–º–æ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –æ–±–ª–∞–¥–Ω–∞–Ω–Ω—è
print("=" * 50)
print("üé® TEST_EASY Colab Server")
print("=" * 50)
print(f"‚úÖ GPU –¥–æ—Å—Ç—É–ø–Ω–∞: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"‚úÖ GPU –º–æ–¥–µ–ª—å: {torch.cuda.get_device_name(0)}")
    print(f"‚úÖ CUDA –≤–µ—Ä—Å—ñ—è: {torch.version.cuda}")

# ============================================================================
# üîß –ö–õ–Ü–¢–ò–ù–ö–ê 3: –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ easy_wrapper.py
# ============================================================================

# –ó–∞–≤–∞–Ω—Ç–∞–∂–∏–º–æ –∫–æ–¥ –∑ TEST_EASY/server/easy_wrapper.py
# –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç–∏, –º–∏ –≤–±—É–¥—É—î–º–æ –∫–æ–¥ —Ç—É—Ç

from diffusers import (
    StableDiffusionPipeline,
    StableDiffusionImg2ImgPipeline,
    StableDiffusionInpaintPipeline,
)

class SimpleGenerator:
    """–°–ø—Ä–æ—â–µ–Ω–∞ –≤–µ—Ä—Å—ñ—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞"""
    
    def __init__(self):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.dtype = torch.float16 if torch.cuda.is_available() else torch.float32
        self.txt2img_pipeline = None
        self.img2img_pipeline = None
        self.inpaint_pipeline = None
        self.current_checkpoint = None
    
    def _load_checkpoint(self, checkpoint_name: str):
        """–ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ checkpoint"""
        if self.current_checkpoint == checkpoint_name:
            return
        
        print(f"üì¶ –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ: {checkpoint_name}")
        
        # –î–µ—Ñ–æ–ª—Ç–Ω—ñ checkpoint'–∏
        checkpoints = {
            "sd15": "runwayml/stable-diffusion-v1-5",
            "sd21": "stabilityai/stable-diffusion-2-1",
            "sdxl": "stabilityai/stable-diffusion-xl-base-1.0",
        }
        
        model_id = checkpoints.get(checkpoint_name, checkpoint_name)
        
        self.txt2img_pipeline = StableDiffusionPipeline.from_pretrained(
            model_id,
            torch_dtype=self.dtype,
            safety_checker=None,
        ).to(self.device)
        
        self.txt2img_pipeline.enable_attention_slicing()
        self.current_checkpoint = checkpoint_name
        print(f"‚úÖ Checkpoint –≥–æ—Ç–æ–≤–∏–π: {checkpoint_name}")
    
    def txt2img(self, prompt, negative_prompt="", checkpoint="sd15", width=512, height=512, steps=20, scale=7.5, seed=-1):
        """txt2img –≥–µ–Ω–µ—Ä–∞—Ü—ñ—è"""
        self._load_checkpoint(checkpoint)
        
        if seed >= 0:
            generator = torch.Generator(self.device).manual_seed(seed)
        else:
            generator = None
        
        with torch.no_grad():
            result = self.txt2img_pipeline(
                prompt=prompt,
                negative_prompt=negative_prompt,
                height=height,
                width=width,
                num_inference_steps=steps,
                guidance_scale=scale,
                generator=generator,
            )
        
        return result.images[0]
    
    def img2img(self, prompt, image_pil, negative_prompt="", checkpoint="sd15", strength=0.75, steps=20, scale=7.5, seed=-1):
        """img2img –≥–µ–Ω–µ—Ä–∞—Ü—ñ—è"""
        self._load_checkpoint(checkpoint)
        
        if self.img2img_pipeline is None:
            self.img2img_pipeline = StableDiffusionImg2ImgPipeline(
                **self.txt2img_pipeline.components
            ).to(self.device)
        
        if seed >= 0:
            generator = torch.Generator(self.device).manual_seed(seed)
        else:
            generator = None
        
        with torch.no_grad():
            result = self.img2img_pipeline(
                prompt=prompt,
                image=image_pil,
                strength=strength,
                num_inference_steps=steps,
                guidance_scale=scale,
                generator=generator,
                negative_prompt=negative_prompt,
            )
        
        return result.images[0]
    
    def inpaint(self, prompt, image_pil, mask_pil, negative_prompt="", checkpoint="sd15", steps=20, scale=7.5, seed=-1):
        """inpaint –≥–µ–Ω–µ—Ä–∞—Ü—ñ—è"""
        self._load_checkpoint(checkpoint)
        
        if self.inpaint_pipeline is None:
            self.inpaint_pipeline = StableDiffusionInpaintPipeline(
                **self.txt2img_pipeline.components
            ).to(self.device)
        
        if seed >= 0:
            generator = torch.Generator(self.device).manual_seed(seed)
        else:
            generator = None
        
        mask_pil = mask_pil.resize(image_pil.size)
        
        with torch.no_grad():
            result = self.inpaint_pipeline(
                prompt=prompt,
                image=image_pil,
                mask_image=mask_pil,
                num_inference_steps=steps,
                guidance_scale=scale,
                generator=generator,
                negative_prompt=negative_prompt,
            )
        
        return result.images[0]

# –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞
generator = SimpleGenerator()

# ============================================================================
# üåê –ö–õ–Ü–¢–ò–ù–ö–ê 4: Flask —Å–µ—Ä–≤–µ—Ä
# ============================================================================

app = Flask(__name__)
CORS(app)

def image_to_base64(image):
    """–ö–æ–Ω–≤–µ—Ä—Ç—É–≤–∞—Ç–∏ PIL Image –≤ base64"""
    buffered = io.BytesIO()
    image.save(buffered, format="PNG")
    return base64.b64encode(buffered.getvalue()).decode()

def base64_to_image(img_base64):
    """–ö–æ–Ω–≤–µ—Ä—Ç—É–≤–∞—Ç–∏ base64 –≤ PIL Image"""
    img_data = base64.b64decode(img_base64)
    return Image.open(io.BytesIO(img_data))

@app.route('/status', methods=['GET'])
def status():
    """–°—Ç–∞—Ç—É—Å —Å–µ—Ä–≤–µ—Ä–∞"""
    return jsonify({
        'status': 'ready',
        'device': generator.device,
        'gpu_available': torch.cuda.is_available(),
        'current_checkpoint': generator.current_checkpoint,
    })

@app.route('/txt2img', methods=['POST'])
def txt2img_endpoint():
    """txt2img endpoint"""
    try:
        data = request.json
        
        prompt = data.get('prompt', '')
        negative_prompt = data.get('negative_prompt', '')
        checkpoint = data.get('checkpoint', 'sd15')
        width = data.get('width', 512)
        height = data.get('height', 512)
        steps = data.get('steps', 20)
        scale = data.get('scale', 7.5)
        seed = data.get('seed', -1)
        
        print(f"üé® txt2img: {prompt[:50]}...")
        
        image = generator.txt2img(
            prompt=prompt,
            negative_prompt=negative_prompt,
            checkpoint=checkpoint,
            width=width,
            height=height,
            steps=steps,
            scale=scale,
            seed=seed,
        )
        
        img_base64 = image_to_base64(image)
        
        return jsonify({
            'success': True,
            'image': img_base64,
        })
    
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 400

@app.route('/img2img', methods=['POST'])
def img2img_endpoint():
    """img2img endpoint"""
    try:
        data = request.json
        
        prompt = data.get('prompt', '')
        negative_prompt = data.get('negative_prompt', '')
        image_base64 = data.get('image', '')
        checkpoint = data.get('checkpoint', 'sd15')
        strength = data.get('strength', 0.75)
        steps = data.get('steps', 20)
        scale = data.get('scale', 7.5)
        seed = data.get('seed', -1)
        
        image = base64_to_image(image_base64)
        
        print(f"üñºÔ∏è  img2img: {prompt[:50]}...")
        
        result_image = generator.img2img(
            prompt=prompt,
            image_pil=image,
            negative_prompt=negative_prompt,
            checkpoint=checkpoint,
            strength=strength,
            steps=steps,
            scale=scale,
            seed=seed,
        )
        
        img_base64 = image_to_base64(result_image)
        
        return jsonify({
            'success': True,
            'image': img_base64,
        })
    
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 400

@app.route('/inpaint', methods=['POST'])
def inpaint_endpoint():
    """inpaint endpoint"""
    try:
        data = request.json
        
        prompt = data.get('prompt', '')
        negative_prompt = data.get('negative_prompt', '')
        image_base64 = data.get('image', '')
        mask_base64 = data.get('mask', '')
        checkpoint = data.get('checkpoint', 'sd15')
        steps = data.get('steps', 20)
        scale = data.get('scale', 7.5)
        seed = data.get('seed', -1)
        
        image = base64_to_image(image_base64)
        mask = base64_to_image(mask_base64)
        
        print(f"üé≠ inpaint: {prompt[:50]}...")
        
        result_image = generator.inpaint(
            prompt=prompt,
            image_pil=image,
            mask_pil=mask,
            negative_prompt=negative_prompt,
            checkpoint=checkpoint,
            steps=steps,
            scale=scale,
            seed=seed,
        )
        
        img_base64 = image_to_base64(result_image)
        
        return jsonify({
            'success': True,
            'image': img_base64,
        })
    
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 400

# ============================================================================
# üöÄ –ö–õ–Ü–¢–ò–ù–ö–ê 5: –ó–∞–ø—É—Å—Ç–∏—Ç–∏ —Å–µ—Ä–≤–µ—Ä
# ============================================================================

if __name__ == '__main__':
    print("\n" + "=" * 50)
    print("üöÄ –ó–∞–ø—É—Å–∫–∞—î–º–æ Flask —Å–µ—Ä–≤–µ—Ä")
    print("=" * 50)
    
    # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ ngrok –¥–ª—è –ø—É–±–ª—ñ—á–Ω–æ–≥–æ –¥–æ—Å—Ç—É–ø—É
    if ngrok:
        print("\nüåê –í—Å—Ç–∞–Ω–æ–≤–ª—é—î–º–æ ngrok —Ç—É–Ω–Ω–µ–ª—å...")
        
        # –ó–∞–ø—É—Å—Ç–∏—Ç–∏ Flask –ª–æ–∫–∞–ª—å–Ω–æ
        from threading import Thread
        
        def run_app():
            app.run(port=5000, debug=False, use_reloader=False)
        
        thread = Thread(target=run_app, daemon=True)
        thread.start()
        
        # –í—Å—Ç–∞–Ω–æ–≤–∏—Ç–∏ ngrok —Ç—É–Ω–Ω–µ–ª—å
        public_url = ngrok.connect(5000)
        
        print(f"\n‚úÖ –°–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω–æ!")
        print(f"‚úÖ –ü—É–±–ª—ñ—á–Ω–µ –ø–æ—Å–∏–ª–∞–Ω–Ω—è: {public_url}")
        print(f"\nüìå –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ —Ü–µ –ø–æ—Å–∏–ª–∞–Ω–Ω—è —É –∫–ª—ñ—î–Ω—Ç—ñ:")
        print(f"   {public_url}")
        
        # –¢—Ä–∏–º–∞—Ç–∏ —Å–µ—Ä–≤–µ—Ä –∂–∏–≤–∏–º
        import time
        try:
            while True:
                time.sleep(1)
        except KeyboardInterrupt:
            print("\n‚ùå –°–µ—Ä–≤–µ—Ä –∑—É–ø–∏–Ω–µ–Ω–æ")
    else:
        # –ó–∞–ø—É—Å—Ç–∏—Ç–∏ –±–µ–∑ ngrok
        print("‚ö†Ô∏è  ngrok –Ω–µ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ. –ó–∞–ø—É—Å–∫–∞—î–º–æ –ª–æ–∫–∞–ª—å–Ω–æ...")
        app.run(host='0.0.0.0', port=5000, debug=False)
